{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12eb2b5-2250-4aa4-9739-dcbd937fc3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell first\n",
    "import requests\n",
    "import lib\n",
    "\n",
    "url = \"http://127.0.0.1:11434/api/generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c618ef4-4b93-48d8-a4bc-751af22982b4",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook demonstrates a range of language models available via Ollama (https://github.com/ollama/ollama).\n",
    "Ollama spins up a service that downloads and runs models for you via CLI commands or a dedicated REST API (meaning it can be easily integrated into any web app). Hence, this notebook does not use any dependencies except standard python stuff (HTTP Requests).\n",
    "\n",
    "Which language models can be used depends on their weights' size, since they have to be loaded exhaustively into the system memory. In our case, a Raspberry Pi 5 with 8GB of RAM provides roughly 7GB of memory available to an AI Model. This makes many models with 7bn parameters work - yet not all of them, since their weights' sizes (I came across) vary between 4-15GB.\n",
    "\n",
    "### Setup\n",
    "See the repo's tutorial to learn how to spin up the Ollama service\n",
    "\n",
    "### Available Models\n",
    "Browse models available for ollama:\n",
    "https://ollama.com/search\n",
    "\n",
    "Tested models are:\n",
    "- `phi3` (3.8b)\n",
    "- `deepseek-r1` (7b)\n",
    "- `llama3.2`(3.8b)\n",
    "- `moondream` (1.8b, multi-modal)\n",
    "- `codellama` (7b)\n",
    "\n",
    "--------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d272a27-afea-466a-9c98-390932cc51bb",
   "metadata": {},
   "source": [
    "### Demos\n",
    "\n",
    "#### (One-Way) Chat\n",
    "Currently, there is no implemented way to engage in a full chat with chat history from within Jupyter. So far, you can only receive text based on your last prompt only.\n",
    "See the repo's documentation in order to learn how to have a more usual chat experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5499479-ebcd-46aa-ad5b-c69d99ade091",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = True\n",
    "\n",
    "data = {\n",
    "    \"model\": \"llama3.2\", # set model name here\n",
    "    \"prompt\": \"who won the 2022 Champions League in soccer?\"\n",
    "}\n",
    "result = requests.post(url, json=data, stream=stream)\n",
    "\n",
    "response_to_prompt = lib.extract_response_stream(result) if stream else lib.extract_responses(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6a4a4-0a26-4092-a420-78bac4bc2b34",
   "metadata": {},
   "source": [
    "#### Discuss Images\n",
    "Multi-modal models (so far, only `moondream` is tested) can accept more than just text input. In this case we pass a text prompt along with an image to the model. The prompt asks a question about the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdf3c3-f051-40b3-bfa7-9a560786ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = True\n",
    "\n",
    "data = {\n",
    "    \"model\": \"moondream\",\n",
    "    \"prompt\": \"what life forms can be seen?\",\n",
    "    \"images\": [lib.image_to_base64(\"output/cat.png\")]\n",
    "}\n",
    "\n",
    "# https://github.com/ollama/ollama/issues/7733\n",
    "result = requests.post(url, json=data, stream=stream)\n",
    "\n",
    "response_to_image = lib.extract_response_stream(result) if stream else lib.extract_responses(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
